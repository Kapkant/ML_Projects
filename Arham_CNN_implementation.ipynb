{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/bhatiaparteek/ml_with_python/blob/main/CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "sauxqgV6lDSm",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#CNN Implementation assignment by Arham Khan\n",
    "#for CS 200 Machine Learning\n",
    "\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers  import MaxPooling2D\n",
    "from keras.layers  import Flatten\n",
    "from keras.layers  import Dense\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "6wM88LOelAQ9",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Initialising CNN\n",
    "classifier = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "nyeoSAXrl5Xv",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# beginngin with convolution\n",
    "classifier.add(Conv2D(filters=32, kernel_size=3,  activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "nFykLLk_mJLP",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#now pooling\n",
    "classifier.add(MaxPooling2D(pool_size=2, strides=2) ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Adding a second convolution and pooling\n",
    "classifier.add(Conv2D(filters=32, kernel_size=3,  activation='relu'))\n",
    "classifier.add(MaxPooling2D(pool_size=2, strides=2) ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "F-lZVDeNmRIL",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# now flattening\n",
    "classifier.add(Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "Ce-4J0q1mXyN",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#full Connection\n",
    "classifier.add(Dense(units=128,  activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "nlBJ1A8emvuZ",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# now output Layer\n",
    "classifier.add(Dense(units=1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "wxDhZ6C-nJWr",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Compilation of CNN\n",
    "classifier.compile( optimizer = 'adam' , loss = 'binary_crossentropy' , metrics =  ['accuracy' ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "3gANO1NNncVm",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Augmenting image\n",
    "train_datagen = ImageDataGenerator(\n",
    "rescale=1. /255,\n",
    "shear_range=0.2,\n",
    "zoom_range=0.2,\n",
    "horizontal_flip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 444
    },
    "id": "jzayinTHnqoI",
    "outputId": "3aacaa90-22ed-4298-9348-c4343c01d6e8",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "training_set = train_datagen.flow_from_directory('/Users/kenfritzell/Downloads/train' ,\n",
    "                                target_size=(128, 128) ,\n",
    "                                batch_size=32,\n",
    "                                class_mode='binary')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "67u4kw0Sn37w",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Image augmentation relative to test data \n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4RJ7YUjXw9ci",
    "outputId": "0d88fefe-c3eb-48dc-c1b9-d45547270079",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "test_set = test_datagen.flow_from_directory(\"/Users/kenfritzell/Downloads/test\",    \n",
    "                                          target_size = (128, 128), \n",
    "                                          batch_size = 32,\n",
    "                                          class_mode=\"binary\")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "amV86mglw_jr",
    "outputId": "c52c6a22-fb32-4049-9392-1fd4dbda64c7",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-14 14:35:14.787689: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - ETA: 0s - loss: 0.7071 - accuracy: 0.5456"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-14 14:35:44.259288: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 800 batches). You may need to use the repeat() function when building your dataset.\n",
      "100/100 [==============================] - 33s 315ms/step - loss: 0.7071 - accuracy: 0.5456 - val_loss: 0.7142 - val_accuracy: 0.5400\n",
      "Epoch 2/50\n",
      "100/100 [==============================] - 28s 276ms/step - loss: 0.6653 - accuracy: 0.5867\n",
      "Epoch 3/50\n",
      "100/100 [==============================] - 28s 281ms/step - loss: 0.6423 - accuracy: 0.6492\n",
      "Epoch 4/50\n",
      "100/100 [==============================] - 29s 288ms/step - loss: 0.6195 - accuracy: 0.6630\n",
      "Epoch 5/50\n",
      "100/100 [==============================] - 28s 277ms/step - loss: 0.5960 - accuracy: 0.6853\n",
      "Epoch 6/50\n",
      "100/100 [==============================] - 28s 279ms/step - loss: 0.5716 - accuracy: 0.6994\n",
      "Epoch 7/50\n",
      "100/100 [==============================] - 28s 279ms/step - loss: 0.5565 - accuracy: 0.7139\n",
      "Epoch 8/50\n",
      "100/100 [==============================] - 28s 275ms/step - loss: 0.5391 - accuracy: 0.7253\n",
      "Epoch 9/50\n",
      "100/100 [==============================] - 27s 274ms/step - loss: 0.5347 - accuracy: 0.7387\n",
      "Epoch 10/50\n",
      "100/100 [==============================] - 27s 271ms/step - loss: 0.5261 - accuracy: 0.7306\n",
      "Epoch 11/50\n",
      "100/100 [==============================] - 28s 279ms/step - loss: 0.5188 - accuracy: 0.7419\n",
      "Epoch 12/50\n",
      "100/100 [==============================] - 28s 281ms/step - loss: 0.5033 - accuracy: 0.7419\n",
      "Epoch 13/50\n",
      "100/100 [==============================] - 27s 271ms/step - loss: 0.4998 - accuracy: 0.7547\n",
      "Epoch 14/50\n",
      "100/100 [==============================] - 28s 282ms/step - loss: 0.4875 - accuracy: 0.7619\n",
      "Epoch 15/50\n",
      "100/100 [==============================] - 28s 277ms/step - loss: 0.5010 - accuracy: 0.7553\n",
      "Epoch 16/50\n",
      "100/100 [==============================] - 27s 273ms/step - loss: 0.4715 - accuracy: 0.7812\n",
      "Epoch 17/50\n",
      "100/100 [==============================] - 29s 287ms/step - loss: 0.4729 - accuracy: 0.7684\n",
      "Epoch 18/50\n",
      "100/100 [==============================] - 29s 291ms/step - loss: 0.4499 - accuracy: 0.7869\n",
      "Epoch 19/50\n",
      "100/100 [==============================] - 28s 281ms/step - loss: 0.4507 - accuracy: 0.7827\n",
      "Epoch 20/50\n",
      "100/100 [==============================] - 30s 296ms/step - loss: 0.4554 - accuracy: 0.7919\n",
      "Epoch 21/50\n",
      "100/100 [==============================] - 29s 288ms/step - loss: 0.4200 - accuracy: 0.8062\n",
      "Epoch 22/50\n",
      "100/100 [==============================] - 29s 288ms/step - loss: 0.4294 - accuracy: 0.8009\n",
      "Epoch 23/50\n",
      "100/100 [==============================] - 30s 296ms/step - loss: 0.4215 - accuracy: 0.8040\n",
      "Epoch 24/50\n",
      "100/100 [==============================] - 30s 300ms/step - loss: 0.4199 - accuracy: 0.8012\n",
      "Epoch 25/50\n",
      "100/100 [==============================] - 31s 304ms/step - loss: 0.4172 - accuracy: 0.8056\n",
      "Epoch 26/50\n",
      "100/100 [==============================] - 30s 298ms/step - loss: 0.4024 - accuracy: 0.8150\n",
      "Epoch 27/50\n",
      "100/100 [==============================] - 31s 307ms/step - loss: 0.4009 - accuracy: 0.8141\n",
      "Epoch 28/50\n",
      "100/100 [==============================] - 31s 305ms/step - loss: 0.3801 - accuracy: 0.8226\n",
      "Epoch 29/50\n",
      "100/100 [==============================] - 30s 297ms/step - loss: 0.3997 - accuracy: 0.8178\n",
      "Epoch 30/50\n",
      "100/100 [==============================] - 31s 309ms/step - loss: 0.3795 - accuracy: 0.8250\n",
      "Epoch 31/50\n",
      "100/100 [==============================] - 31s 309ms/step - loss: 0.3936 - accuracy: 0.8191\n",
      "Epoch 32/50\n",
      "100/100 [==============================] - 33s 329ms/step - loss: 0.3670 - accuracy: 0.8363\n",
      "Epoch 33/50\n",
      "100/100 [==============================] - 38s 380ms/step - loss: 0.3680 - accuracy: 0.8369\n",
      "Epoch 34/50\n",
      "100/100 [==============================] - 30s 301ms/step - loss: 0.3773 - accuracy: 0.8266\n",
      "Epoch 35/50\n",
      "100/100 [==============================] - 29s 290ms/step - loss: 0.3622 - accuracy: 0.8363\n",
      "Epoch 36/50\n",
      "100/100 [==============================] - 30s 302ms/step - loss: 0.3766 - accuracy: 0.8291\n",
      "Epoch 37/50\n",
      "100/100 [==============================] - 32s 315ms/step - loss: 0.3474 - accuracy: 0.8475\n",
      "Epoch 38/50\n",
      "100/100 [==============================] - 31s 307ms/step - loss: 0.3488 - accuracy: 0.8469\n",
      "Epoch 39/50\n",
      "100/100 [==============================] - 31s 305ms/step - loss: 0.3453 - accuracy: 0.8403\n",
      "Epoch 40/50\n",
      "100/100 [==============================] - 33s 324ms/step - loss: 0.3360 - accuracy: 0.8587\n",
      "Epoch 41/50\n",
      "100/100 [==============================] - 31s 309ms/step - loss: 0.3191 - accuracy: 0.8656\n",
      "Epoch 42/50\n",
      "100/100 [==============================] - 32s 320ms/step - loss: 0.3276 - accuracy: 0.8550\n",
      "Epoch 43/50\n",
      "100/100 [==============================] - 32s 320ms/step - loss: 0.3136 - accuracy: 0.8637\n",
      "Epoch 44/50\n",
      "100/100 [==============================] - 31s 311ms/step - loss: 0.3201 - accuracy: 0.8643\n",
      "Epoch 45/50\n",
      "100/100 [==============================] - 32s 315ms/step - loss: 0.3103 - accuracy: 0.8687\n",
      "Epoch 46/50\n",
      "100/100 [==============================] - 33s 325ms/step - loss: 0.3152 - accuracy: 0.8669\n",
      "Epoch 47/50\n",
      "100/100 [==============================] - 32s 318ms/step - loss: 0.3163 - accuracy: 0.8678\n",
      "Epoch 48/50\n",
      "100/100 [==============================] - 33s 325ms/step - loss: 0.3036 - accuracy: 0.8703\n",
      "Epoch 49/50\n",
      "100/100 [==============================] - 33s 325ms/step - loss: 0.2816 - accuracy: 0.8791\n",
      "Epoch 50/50\n",
      "100/100 [==============================] - 33s 328ms/step - loss: 0.3026 - accuracy: 0.8703\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fadf964f0d0>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#using training set to train CNN and evaluating using testing set\n",
    "classifier.fit(training_set,\n",
    "                        steps_per_epoch=100,\n",
    "                         epochs=50,\n",
    "                         validation_data=test_set,\n",
    "                         validation_steps=800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "t_gRB6NKxCRM",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Making prediction \n",
    "import numpy as np\n",
    "\n",
    "#importing image from keras.preprocessing\n",
    "from tensorflow.keras.preprocessing import image\n",
    "unseen_image = image.load_img(\"/Users/khana/Documents/bruno.jpg\",target_size = (128, 128))\n",
    "unseen_image  = image.img_to_array(unseen_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RGgblCIxxLhl",
    "outputId": "48968181-f065-4d12-fb66-aa631c53d67a",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 134ms/step\n",
      "The given image is of dog\n"
     ]
    }
   ],
   "source": [
    "unseen_image  = np.expand_dims(unseen_image,  axis  = 0)\n",
    "result  =  classifier.predict(unseen_image)\n",
    "training_set.class_indices\n",
    "if  result[0] [0]  ==1:\n",
    "            prediction  = \"dog\"\n",
    "else :\n",
    "            prediction  = \"bird\"\n",
    "print (\"The given image is of \"+prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "include_colab_link": true,
   "name": "CNN",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
